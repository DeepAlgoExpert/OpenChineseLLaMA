[**ä¸­æ–‡**](./README.md) | [**English**](./README_EN.md)

# Open-Chinese-LLaMA

[![](https://img.shields.io/github/license/OpenLMLab/OpenChineseLLaMA?label=Code%20License)]()[![Model License](https://img.shields.io/badge/Model%20License-Apache_2.0-green.svg)]()[![](https://img.shields.io/github/last-commit/OpenLMLab/OpenChineseLLaMA)]()[![](https://img.shields.io/github/issues/OpenLMLab/OpenChineseLLaMA)]()

æœ¬é¡¹ç›®ä¸ºåŸºäº [LLaMA](https://github.com/facebookresearch/llama)-7B ç»è¿‡ **ä¸­æ–‡æ•°æ®é›†å¢é‡é¢„è®­ç»ƒ** äº§ç”Ÿçš„ **ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹åŸºåº§**ã€‚

## ç‰¹ç‚¹

* æœ¬é¡¹ç›®ä¸ºé€šè¿‡å…¨é‡å¾®è°ƒï¼ˆFull-tuningï¼‰è·å¾—çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹ï¼Œæä¾› huggingface ç‰ˆæœ¬æƒé‡
* å¯¹æ¯”åŸç‰ˆ LLaMAï¼Œæœ¬æ¨¡å‹åœ¨ä¸­æ–‡ç†è§£èƒ½åŠ›å’Œç”Ÿæˆèƒ½åŠ›æ–¹é¢å‡è·å¾—è¾ƒå¤§æå‡ï¼Œåœ¨ä¼—å¤šä¸‹æ¸¸ä»»åŠ¡ä¸­å‡å–å¾—äº†çªå‡ºçš„æˆç»©ï¼Œè¯¦è§ [è¯„æµ‹](##è¯„æµ‹)
* æœ¬é¡¹ç›®æä¾›äº† Huggingface ç‰ˆæœ¬æƒé‡å’Œ Meta ç‰ˆæœ¬æƒé‡çš„è½¬æ¢å·¥å…·
* æ”¯æŒ [ğŸ¤—transformers](https://github.com/huggingface/transformers)ï¼Œæä¾›å‘½ä»¤è¡Œå·¥å…·æ–¹ä¾¿æµ‹è¯•æ¨¡å‹æ•ˆæœ

## ç›®å½•
* [æ¨¡å‹ä¸‹è½½](##æ¨¡å‹ä¸‹è½½)
* [æœ¬åœ° Demo](##æœ¬åœ°Demo)
* [è¯„æµ‹](##è¯„æµ‹)
* [æ¨¡å‹æ ¼å¼è½¬æ¢](##æ¨¡å‹æ ¼å¼è½¬æ¢)

## æ¨¡å‹ä¸‹è½½

| æ¨¡å‹åç§°                    | æƒé‡ç±»å‹ | ä¸‹è½½åœ°å€                                                     | SHA256                 |
| --------------------------- | -------- | ------------------------------------------------------------ | ---------------------- |
| Open-Chinese-LLaMA-7B-Patch | Patch    | [[ğŸ¤—Huggingface]]() <br> [[ç™¾åº¦ç½‘ç›˜]](https://pan.baidu.com/s/14E7iZKcH-5SHMDu97k70cg?pwd=gk34)<br>[[Google Driver]](https://drive.google.com/drive/folders/1THvuFzq_wojVfMLYV1qsSE_ddSjG0Ypv?usp=sharing) | [SHA256](./SHA256.txt) |

### ä½¿ç”¨é¡»çŸ¥

Meta å®˜æ–¹å‘å¸ƒçš„ [LLaMA](https://github.com/facebookresearch/llama) æœªå¼€æºæƒé‡ï¼Œä¸ºäº†éµå®ˆç›¸å…³è®¸å¯ï¼Œæœ¬æ¬¡å‘å¸ƒçš„æ¨¡å‹ä¸º **è¡¥ä¸ï¼ˆPatchï¼‰** ç±»å‹ï¼Œé¡»é…åˆåŸå§‹å®˜æ–¹æƒé‡æ‰å¯ä»¥ä½¿ç”¨ã€‚

æˆ‘ä»¬æä¾›äº† **è¡¥ä¸ï¼ˆPatchï¼‰** çš„å®‰è£…è„šæœ¬ï¼Œåœ¨é€šè¿‡æ­£è§„æ¸ é“è·å¾—å®˜æ–¹æƒé‡åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å®‰è£…è¡¥ä¸ï¼š

```bash
python tools/patch_model.py --base_model <path_or_name_to_original_model>
                            --patch_model openlmlab/open-chinese-llama-7b-patch
                            --base_model_format <hf_or_raw>
```

æç¤ºï¼šæœ¬è¡¥ä¸çš„å®‰è£…æ–¹å¼ä¸ºåŸåœ°å®‰è£…ï¼Œå³å®‰è£…åçš„è¡¥ä¸å³ä¸ºå®Œæ•´ç‰ˆ huggingface ç‰ˆæœ¬çš„æœ¬æ¨¡å‹æƒé‡ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ transformersåŠ è½½æ¨¡å‹ã€‚

æç¤ºï¼šè¯¥è„šæœ¬ä¾èµ–äº [OpenLMLab/collie](https://github.com/OpenLMLab/collie)ï¼Œè¯·é€šè¿‡ä¸‹é¢çš„å‘½ä»¤å®‰è£…è¯¥æ¡†æ¶ï¼š

```bash
pip install git+https://github.com/OpenLMLab/collie.git
```

## æœ¬åœ° Demo

ä¸ºäº†æ–¹ä¾¿å¿«é€Ÿæµ‹è¯•æ¨¡å‹æ•ˆæœï¼Œæˆ‘ä»¬æä¾›äº†å‘½ä»¤è¡Œç‰ˆæœ¬çš„ Demoï¼Œåœ¨æ‚¨æ ¹æ® [ä½¿ç”¨é¡»çŸ¥](###ä½¿ç”¨é¡»çŸ¥) æˆåŠŸå®‰è£…è¡¥ä¸ä¹‹åï¼Œå¯ä»¥ä½¿ç”¨è„šæœ¬å¯åŠ¨äº¤äº’å¼ç•Œé¢ï¼š

```bash
python cli_demo.py --model openlmlab/open-chinese-llama-7b-patch
                   --devices 0
                   --max_length 1024
                   --do_sample true
                   --top_k 40
                   --top_p 0.8
                   --temperature 0.7
                   --penalty 1.02
```

### ç¤ºä¾‹

å·¦ä¾§ä¸º Open-Chinese-LLaMA-7Bï¼Œå³ä¾§ä¸ºåŸç‰ˆ LLaMAï¼š

<div align=center><img src="./pics/cli_demo1.png"></div>
<center style="font-size:14px;color:#C0C0C0;text-decoration:underline">æ–‡æœ¬ç»­å†™</center>
<br>
<div align=center><img src="./pics/cli_demo2.png"></div>
<center style="font-size:14px;color:#C0C0C0;text-decoration:underline">ä»£ç ç”Ÿæˆ</center>
<br>
<div align=center><img src="./pics/cli_demo3.png"></div>
<center style="font-size:14px;color:#C0C0C0;text-decoration:underline">æŒ‡ä»¤ï¼ˆæ³¨ï¼šå‡æœªç»è¿‡ Instruct-tuningï¼‰</center>
<br>

## è¯„æµ‹

Open-Chinese-LLaMA-7B åœ¨ä¸­è‹±æ–‡æ•°æ®é›†çš„å¤šç§ä»»åŠ¡ä¸Šçš„è¡¨ç°éƒ½è¿œè¶…åŸç‰ˆ LLaMAï¼Œä¸‹é¢ç»™å‡ºæœ¬æ¨¡å‹åœ¨éƒ¨åˆ†æ•°æ®é›†ä¸Šçš„è¯„æµ‹ç»“æœï¼ˆä»¥ä¸‹æŒ‡æ ‡å‡ä¸º Accuracyï¼Œè¶Šå¤§è¶Šå¥½ï¼‰ï¼š

| æ•°æ®é›†   | LLAMA 7B | Open-Chinese-LLaMA-7B |
| -------- | -------- | ----------- |
| OCNLI    | 31.5     | 45.5        | 
| CHID     | 25.87    | 71.47       | 
| TNEWS    | 8.70     | 26.78       | 
| CMRC     | 11.89    | 34.48       | 
| PIQA     | 79.8     | 77.31       |
| HumanEval | 10.5    | 14.63       |
| MBPP      | 17.7    | 17.2        |
| å¹³å‡å€¼    | 26.57    | 41.05       |


æ³¨ï¼šå®Œæ•´ç»“æœè§ [Benchmark.md](./benchmark/Benchmark.md)ã€‚

## æ¨¡å‹æ ¼å¼è½¬æ¢

æœ¬é¡¹ç›®ä¸­ `patch_model.py` å·¥å…·ç”Ÿæˆçš„æ¨¡å‹ä¸º transformerså¯åŠ è½½çš„ **hf** æ ¼å¼ã€‚ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬åŒæ—¶æä¾›äº†å®˜æ–¹ç‰ˆæœ¬æ¨¡å‹ï¼ˆrawï¼‰å’Œ hf çš„ç›¸äº’è½¬æ¢å·¥å…·ï¼š

```bash
python convert_model.py --model_path <path_or_name_to_your_hf_or_raw_model>
                        --source_format hf
                        --target_format raw
                        --target_path <path_you_want_to_save_the_converted_model>
                        --raw_parallel_degree 2
                        --raw_parallel_devices 0,1
```

æç¤ºï¼šå½“è½¬æ¢æˆ raw æ ¼å¼çš„æ¨¡å‹æ—¶ï¼Œéœ€è¦æŒ‡å®šå¼ é‡å¹¶è¡Œçš„å¤§å°å’Œå¯¹åº”è®¾å¤‡ï¼Œå¹¶ä¸”åªèƒ½åœ¨æ‹¥æœ‰å¯¹åº”æ•°é‡çš„æ˜¾å¡çš„æœºå™¨ä¸Šè½¬æ¢ã€‚
